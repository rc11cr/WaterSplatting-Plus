import os
import cv2
import torch
import argparse
import numpy as np
from PIL import Image
from tqdm import tqdm
from transformers import pipeline

def generate_depths(data_dir, output_folder="depth"):
    """
    Generate depth maps using Depth Anything V2 (via HuggingFace)
    """
    # 1. Prepare paths
    images_dir = os.path.join(data_dir, "images") # Assuming images generated by ns-process-data are here
    depths_dir = os.path.join(data_dir, output_folder)
    
    if not os.path.exists(images_dir):
        print(f"Error: Images folder not found: {images_dir}")
        print("Please run ns-process-data to generate data first!")
        return

    os.makedirs(depths_dir, exist_ok=True)

    # 2. Load model (automatically downloads Depth Anything V2)
    print("Loading Depth Anything V2 model...")
    device = 0 if torch.cuda.is_available() else -1
    # Use depth-anything-small-hf or large version
    pipe = pipeline(task="depth-estimation", model="LiheYoung/depth-anything-small-hf", device=device)

    # 3. Iterate through images and process
    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
    image_files.sort()

    print(f"Starting processing of {len(image_files)} images...")

    for img_name in tqdm(image_files):
        img_path = os.path.join(images_dir, img_name)
        
        # Read image
        pil_image = Image.open(img_path).convert("RGB")
        
        # Inference
        depth_output = pipe(pil_image)
        depth_map = depth_output["depth"] # This is a PIL Image object

        # --- Critical Step: Save as 16-bit PNG ---
        # Monocular depth is usually relative, we need to preserve precision
        # Map float (0~1 or 0~255) to uint16 (0~65535)
        
        depth_np = np.array(depth_map).astype(np.float32)
        
        # Normalize to 0-1
        depth_min, depth_max = depth_np.min(), depth_np.max()
        depth_norm = (depth_np - depth_min) / (depth_max - depth_min + 1e-6)
        
        # Scale to uint16 range
        depth_uint16 = (depth_norm * 65535).astype(np.uint16)
        
        # Save (keep filename consistent, extension can be .png)
        # Note: Nerfstudio defaults to reading files with the same name in the depth folder
        save_name = os.path.splitext(img_name)[0] + ".png"
        save_path = os.path.join(depths_dir, save_name)
        
        cv2.imwrite(save_path, depth_uint16)

    print(f"âœ… Depth map generation complete! Saved to: {depths_dir}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data", type=str, required=True, help="Root directory of the dataset generated by ns-process-data (containing the images folder)")
    args = parser.parse_args()
    
    generate_depths(args.data)